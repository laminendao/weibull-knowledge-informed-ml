{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal, fftpack\n",
    "import time\n",
    "import datetime\n",
    "# from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import fnmatch\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# suppress matplotlib deprecation warnings\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# to clear outputs from cells\n",
    "from IPython.display import clear_output\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max(x):\n",
    "\n",
    "    # flatten the input array http://bit.ly/2MQuXZd\n",
    "    flat_vector = np.concatenate(x).ravel()\n",
    "\n",
    "    min_val = min(flat_vector)\n",
    "    max_val = max(flat_vector)\n",
    "\n",
    "    return min_val, max_val\n",
    "\n",
    "\n",
    "def scaler(x, min_val, max_val, lower_norm_val=0, upper_norm_val=1):\n",
    "    \"\"\"Scale the signal between a min and max value\n",
    "    \n",
    "    Parameters\n",
    "    ===========\n",
    "    x : ndarray\n",
    "        Signal that is being normalized\n",
    "\n",
    "    max_val : int or float\n",
    "        Maximum value of the signal or dataset\n",
    "\n",
    "    min_val : int or float\n",
    "        Minimum value of the signal or dataset\n",
    "\n",
    "    lower_norm_val : int or float\n",
    "        Lower value you want to normalize the data between (e.g. 0)\n",
    "\n",
    "    upper_norm_val : int or float\n",
    "        Upper value you want to normalize the data between (e.g. 1)\n",
    "\n",
    "    Returns\n",
    "    ===========\n",
    "    x : ndarray\n",
    "        Returns a new array that was been scaled between the upper_norm_val\n",
    "        and lower_norm_val values\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # https://codereview.stackexchange.com/questions/185785/scale-numpy-array-to-certain-range\n",
    "    col, row = np.shape(x)\n",
    "    for i in range(col):\n",
    "        x[i] = np.interp(x[i], (min_val, max_val), (lower_norm_val, upper_norm_val))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the root (parent folder) and the data folder locations\n",
    "folder_root = Path.cwd().parent # get root folder of repository\n",
    "\n",
    "folder_raw_data = folder_root / 'data/raw/FEMTO/Training_set/Learning_set/' # raw data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text file for first measurement\n",
    "# first test folder location\n",
    "folder_bearing1_1 = folder_raw_data / 'Bearing1_1'\n",
    "\n",
    "# let's use pandas\n",
    "col_names = ['hr', 'min', 'sec', 'micro_sec', 'acc_horz', 'acc_vert']\n",
    "df = pd.read_csv(folder_bearing1_1 / 'acc_00001.csv', names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the shape of the dataframe?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the IEEE PHM 2012 Prognostic challenge outline, it says that the collection is at 25.6 kHz for the acceleration signals\n",
    "\n",
    "Other important operating information:\n",
    "\n",
    "* First operating conditions: 1800 rpm and 4000 N\n",
    "* Second operating condition: 1650 rpm and 4200 N\n",
    "* Third operating condition: 1500 rpm and 5000 N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first bearing channel\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(\n",
    "    np.arange(0,df.shape[0], dtype='float64') / (25.6 * 10**3), # make x-axis in seconds\n",
    "    df['acc_horz'] # acceleration data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# practice detrending\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "\n",
    "plt.plot(df['acc_horz'], alpha=0.5, label='original signal')\n",
    "y_detrend = signal.detrend(df['acc_horz'], type=\"linear\")\n",
    "plt.plot(y_detrend, alpha=0.5, label='detrended signal')\n",
    "\n",
    "# apply either a hamming or kaiser windowing function\n",
    "# y_detrend *= np.hamming(len(y_detrend))\n",
    "y_detrend *= np.kaiser(len(y_detrend), 3)\n",
    "plt.plot(y_detrend, alpha=0.5, label='windowed signal')\n",
    "plt.legend(loc='center left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a generic function for plotting the FFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fft(df, x_name='Time', y_name='acc_horz', sample_freq=25600.0, show_plot=True, window='hamming', beta=8):\n",
    "    '''Create FFT plot from a pandas dataframe'''\n",
    "\n",
    "    y = df[y_name].to_numpy(dtype=\"float64\")  # convert to a numpy array\n",
    "    x = np.arange(0,df.shape[0], dtype='float64') / (sample_freq)\n",
    "\n",
    "    # parameters for plot\n",
    "    T = 1.0 / sample_freq  # sample spacing\n",
    "    N = len(y)  # number of sample points\n",
    "    \n",
    "    # do some preprocessing of the current signal\n",
    "    y_detrend = y - np.mean(y)\n",
    "    y_detrend = signal.detrend(y_detrend, type=\"constant\")  # detrended signal\n",
    "    \n",
    "    if window == 'hamming':\n",
    "        y_detrend *= np.hamming(N)  # apply a hamming window. Why? https://dsp.stackexchange.com/a/11323\n",
    "    else:\n",
    "        y_detrend *= np.kaiser(len(y_detrend), beta)\n",
    "\n",
    "    # FFT on time domain signal\n",
    "    yf = fftpack.rfft(y_detrend)\n",
    "    yf = 2.0 / N * np.abs(yf[: int(N / 2.0)])\n",
    "    xf = np.linspace(0.0, 1.0 / (2.0 * T), N // 2)/2\n",
    "\n",
    "    if show_plot:\n",
    "        # setup the seaborn plot\n",
    "        sns.set(font_scale=1.0, style=\"whitegrid\")\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=False, sharey=False)\n",
    "        fig.tight_layout(pad=5.0)\n",
    "\n",
    "        pal = sns.cubehelix_palette(6, rot=-0.25, light=0.7)  # pick nice color for plot\n",
    "\n",
    "        # plot time domain signal\n",
    "        axes[0].plot(x, y, marker=\"\", label=\"Best model\", color=pal[3], linewidth=0.8)\n",
    "        axes[0].set_title(\"Time Domain\", fontdict={\"fontweight\": \"normal\"})\n",
    "        axes[0].set_xlabel(\"Time (seconds)\")\n",
    "        axes[0].set_ylabel(\"Acceleration, g\")\n",
    "        # axes[0].set_yticklabels([])\n",
    "\n",
    "        # plot the frequency domain signal\n",
    "        axes[1].plot(xf, yf, marker=\"\", label=\"Best model\", color=pal[3], linewidth=0.8)\n",
    "        axes[1].set_title(\"Frequency Domain\", fontdict={\"fontweight\": \"normal\"})\n",
    "        axes[1].set_xlabel(\"Frequency (Hz)\")\n",
    "        axes[1].set_ylabel(\"Acceleration, g\")\n",
    "        plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "        \n",
    "\n",
    "        # clean up the sub-plots to make everything pretty\n",
    "        for ax in axes.flatten():\n",
    "            ax.yaxis.set_tick_params(labelleft=True, which=\"major\")\n",
    "            ax.grid(False)\n",
    "            \n",
    "        # in case you want to save the figure (just uncomment)\n",
    "        plt.savefig('time_freq_domains.png',dpi=600,bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "    \n",
    "    return xf, yf\n",
    "\n",
    "xf, yf = create_fft(df, x_name='Time', y_name='acc_horz', sample_freq=25600.0, show_plot=True, window='kaiser', beta=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_freq(xf, yf, max_freq_to_plot=1000, peak_height=0.0001, peak_distance=100):\n",
    "\n",
    "    # select the index number where xf is less than a certain freq\n",
    "    i = np.where(xf<max_freq_to_plot)[0][-1]\n",
    "    peak_distance_index = peak_distance * i / max_freq_to_plot\n",
    "\n",
    "    # setup the seaborn plot\n",
    "    sns.set(font_scale=1.0, style=\"whitegrid\")\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(12, 8), sharex=False, sharey=False)\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    \n",
    "    pal = sns.cubehelix_palette(6, rot=-0.25, light=0.7)  # pick nice color for plot\n",
    "\n",
    "    # plot the frequency domain signal\n",
    "    axes.plot(xf[:i], yf[:i], marker=\"\", label=\"Best model\", color=pal[3], linewidth=0.8)\n",
    "    axes.set_title(\"Frequency Domain\", fontdict={\"fontweight\": \"normal\"})\n",
    "    axes.set_xlabel(\"Frequency (Hz)\")\n",
    "    axes.set_ylabel(\"Acceleration, g\")\n",
    "    axes.yaxis.set_tick_params(labelleft=True, which=\"major\")\n",
    "    axes.grid(False)\n",
    "\n",
    "    peaks, _ = signal.find_peaks(yf[:i], height=peak_height, distance=peak_distance_index)\n",
    "    plt.plot(xf[peaks], yf[peaks], \"x\", color='#d62728', markersize=10)\n",
    "\n",
    "    for p in peaks:\n",
    "        axes.text(\n",
    "            x=xf[p]+max_freq_to_plot/50.0,\n",
    "            y=yf[p],\n",
    "            s=f\"{xf[p]:.1f} Hz\",\n",
    "            horizontalalignment=\"left\",\n",
    "            verticalalignment=\"center\",\n",
    "            size=12,\n",
    "            color=\"#d62728\",\n",
    "            rotation=\"horizontal\",\n",
    "            weight=\"normal\",\n",
    "        )\n",
    "\n",
    "    plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_freq(xf, yf, max_freq_to_plot=6000, peak_height=0.06, peak_distance=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try a different operating condition -- how about the third operating condition at 1500 RPM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third operating condition folder location\n",
    "folder_bearing3_1 = folder_raw_data / 'Bearing3_1'\n",
    "\n",
    "# let's use pandas\n",
    "col_names = ['hr', 'min', 'sec', 'micro_sec', 'acc_horz', 'acc_vert']\n",
    "df = pd.read_csv(folder_bearing3_1 / 'acc_00001.csv', names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf, yf = create_fft(df, x_name='Time', y_name='acc_horz', sample_freq=25600.0, show_plot=True, window='kaiser', beta=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to bearing1_1\n",
    "df = pd.read_csv(folder_bearing1_1 / 'acc_00001.csv', names=col_names)\n",
    "xf, yf = create_fft(df, x_name='Time', y_name='acc_horz', sample_freq=25600.0, show_plot=True, window='kaiser', beta=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram\n",
    "We want to build a spectrogram for bearing1_1.\n",
    "\n",
    "First, get the name of all the files in the folder.\n",
    "\n",
    "### Aside: Getting Acceleration Files Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_dict(folder):\n",
    "    # instantiate the date dictionary that will\n",
    "    # hold the date/time that each signal was recorded on\n",
    "    # along with the file name\n",
    "\n",
    "    date_dict = {}\n",
    "\n",
    "    for i, file in enumerate(os.listdir(folder)):\n",
    "        if fnmatch.fnmatch(file, f'acc*.csv'):\n",
    "\n",
    "            # get the unix timestamp for when the file was modified (http://bit.ly/2RW5cYo)\n",
    "            date_created = datetime.datetime.fromtimestamp(os.path.getmtime(folder_bearing1_1 / str(file)))\n",
    "\n",
    "            # open each csv file, read first line, and extract times\n",
    "            with open(folder_bearing1_1 / file, newline='') as f:\n",
    "                csv_reader = csv.reader(f)\n",
    "                csv_headings = next(csv_reader)\n",
    "\n",
    "            # help with datetime: https://realpython.com/python-datetime/\n",
    "            # convert \"time\" string to datetime object\n",
    "            time_created = datetime.time(hour=int(float(csv_headings[0])), \n",
    "                                         minute=int(float(csv_headings[1])), \n",
    "                                         second=int(float(csv_headings[2])), \n",
    "                                         microsecond=int(float(csv_headings[3]))\n",
    "                                         )\n",
    "\n",
    "            # combine date and time into a single datetime object\n",
    "            combined_date = datetime.datetime.combine(date_created, time_created)\n",
    "            unix_timestamp = combined_date.timestamp()\n",
    "            date_nice_format = combined_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            date_dict[unix_timestamp] = [combined_date, date_nice_format, file]\n",
    "    return date_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_bearing1_1 = folder_raw_data / 'Bearing1_1'\n",
    "\n",
    "date_dict = create_date_dict(folder_bearing1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate FFT for Each Signal\n",
    "We'll calculate the FFT for each signal. This will be stored in a pandas dataframe, with each new column being a new signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_spectrogram_df_femto(folder, date_dict, channel_name='acc_horz', col_day_increment=False,\n",
    "                         col_names=['hr', 'min', 'sec', 'micro_sec', 'acc_horz', 'acc_vert']):\n",
    "    '''function that builds the spectrogram data'''\n",
    "    \n",
    "    # date_time list\n",
    "    date_list = sorted(list(date_dict.keys()))\n",
    "    start_time = date_list[0] # get the star time\n",
    "\n",
    "    # instantiate dataframe for the spectrogram\n",
    "    dft = pd.DataFrame()\n",
    "       \n",
    "    # dictionary to store any labels\n",
    "    labels_dict = {}\n",
    "\n",
    "    # iterate through each date that samples were taken\n",
    "    # date_list should be sorted from earliest to latest\n",
    "    for i, unix_timestamp in enumerate(date_list):\n",
    "        # convert sample_name to unix timestamp\n",
    "        date_nice_format = date_dict[unix_timestamp][1]\n",
    "\n",
    "        # open the file containing the measurements\n",
    "        df = pd.read_csv(folder / date_dict[unix_timestamp][2], names=col_names)\n",
    "\n",
    "        # create fft\n",
    "        xf, yf = create_fft(df, x_name='Time', y_name=channel_name, sample_freq=25600.0, show_plot=False, window='kaiser', beta=3)\n",
    "        # xf, yf = create_fft(df, x_name='Time', y_name=channel_name, sample_freq=20000.0, show_plot=False, window='kaiser', beta=3)\n",
    "\n",
    "\n",
    "        # append the time increments\n",
    "        time_increment_seconds = unix_timestamp-start_time\n",
    "        time_increment_days = time_increment_seconds /(60 * 60 * 24)\n",
    "        \n",
    "        # create new column for the current sample_name FFT\n",
    "        if col_day_increment == False:\n",
    "            dft[date_nice_format] = yf\n",
    "        if col_day_increment == True:\n",
    "            dft[str(time_increment_days)] = yf\n",
    "\n",
    "        # create new dictionary key and values to store lable info\n",
    "        labels_dict[unix_timestamp] = [date_nice_format, unix_timestamp, time_increment_seconds, time_increment_days]\n",
    "\n",
    "    dft = dft.set_index(xf, drop=True) # index as frequency (Hz)\n",
    "    return dft, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_bearing1_1 = folder_raw_data / 'Bearing1_1'\n",
    "\n",
    "date_dict = create_date_dict(folder_bearing1_1)\n",
    "\n",
    "df_spec, labels_dict = build_spectrogram_df_femto(folder_bearing1_1, date_dict, channel_name='acc_horz',)\n",
    "df_spec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "plt.pcolormesh(df_spec.columns, df_spec.index, df_spec)\n",
    "\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "plt.xticks(df_spec.columns[::200]) # show every 100th date on x-axis ticks\n",
    "plt.xticks(rotation=75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above spectrogram is fairly \"dim\". \n",
    "\n",
    "We'll adjust the vmax to get better clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "# set vmax to 0.2\n",
    "plt.pcolormesh(df_spec.columns, df_spec.index, df_spec, vmax=0.2)\n",
    "\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "plt.xticks(df_spec.columns[::100]) # show every 100th date on x-axis ticks\n",
    "plt.xticks(rotation=75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_bearing1_1 = folder_raw_data / 'Bearing1_1'\n",
    "\n",
    "date_dict = create_date_dict(folder_bearing1_1)\n",
    "\n",
    "df_spec, labels_dict = build_spectrogram_df_femto(folder_bearing1_1, date_dict, channel_name='acc_horz',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_size = 64\n",
    "\n",
    "df_temp = df_spec\n",
    "a = np.array(df_temp) # make numpy array\n",
    "\n",
    "# get the y-axis (frequency values)\n",
    "y = np.array(df_temp.index)\n",
    "y = np.max(y.reshape(-1,bucket_size),axis=1)\n",
    "\n",
    "# get the max value for each bucket\n",
    "# https://stackoverflow.com/a/15956341/9214620\n",
    "max_a = np.max(a.reshape(-1,bucket_size,2802),axis=1)\n",
    "\n",
    "print('shape of max_a array:', np.shape(max_a))\n",
    "\n",
    "# get the mean value for each bucket\n",
    "avg_a = np.mean(a.reshape(-1,bucket_size,2802),axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "plt.pcolormesh(df_temp.columns, y, max_a)\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "plt.xticks(df_temp.columns[::200])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(max_a.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
